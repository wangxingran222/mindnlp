{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初始化模型与配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n"
     ]
    }
   ],
   "source": [
    "import torch, mindspore\n",
    "import mindspore.ops as ops\n",
    "import numpy as np\n",
    "from transformers.models.bart import modeling_bart as pt\n",
    "import mindnlp.models.bart as m\n",
    "\n",
    "# init config\n",
    "ms_config = m.BartConfig()\n",
    "pt_config = pt.BartConfig()\n",
    "# pt_config.activation_function = \"gelu_new\"\n",
    "\n",
    "# init model\n",
    "ms_model = m.BartForCausalLM(ms_config)\n",
    "pt_model = pt.BartForCausalLM(pt_config)\n",
    "\n",
    "seq_len = 64\n",
    "batch = 4\n",
    "embed_dim = ms_config.d_model\n",
    "tgt_len = 32\n",
    "src_len = 32\n",
    "encoder_attention_heads = ms_config.encoder_attention_heads\n",
    "\n",
    "hidden_states = np.random.randn(batch,seq_len,embed_dim)\n",
    "# input_ids = np.random.randint(128,None,(batch,seq_len))\n",
    "input_ids = np.array([\n",
    "                [71, 82, 18, 33, 46, 91, 2],\n",
    "                [68, 34, 26, 58, 30, 82, 2],\n",
    "                [5, 97, 17, 39, 94, 40, 2],\n",
    "                [76, 83, 94, 25, 70, 78, 2],\n",
    "                [87, 59, 41, 35, 48, 66, 2],\n",
    "                [55, 13, 16, 58, 5, 2, 1],  # note padding\n",
    "                [64, 27, 31, 51, 12, 75, 2],\n",
    "                [52, 64, 86, 17, 83, 39, 2],\n",
    "                [48, 61, 9, 24, 71, 82, 2],\n",
    "                [26, 1, 60, 48, 22, 13, 2],\n",
    "                [21, 5, 62, 28, 14, 76, 2],\n",
    "                [45, 98, 37, 86, 59, 48, 2],\n",
    "                [70, 70, 50, 9, 28, 0, 2],\n",
    "                [70, 70, 50, 9, 28, 0, 2],\n",
    "                [70, 70, 50, 9, 28, 0, 2],\n",
    "                [70, 70, 50, 9, 28, 0, 2],\n",
    "                [70, 70, 50, 9, 28, 0, 2],\n",
    "                [70, 70, 50, 9, 28, 0, 2],\n",
    "                [70, 70, 50, 9, 28, 0, 2],\n",
    "                [70, 70, 50, 9, 28, 0, 2],\n",
    "                [70, 70, 50, 9, 28, 0, 2],\n",
    "                [70, 70, 50, 9, 28, 0, 2],\n",
    "                [70, 70, 50, 9, 28, 0, 2],\n",
    "                [70, 70, 50, 9, 28, 0, 2],\n",
    "            ])\n",
    "# attention_mask = np.random.randint(0,1,(batch,seq_len))\n",
    "attention_mask = np.random.randn(batch,1,seq_len,seq_len)\n",
    "head_mask = np.random.randint(0,1,(ms_config.encoder_layers,ms_config.encoder_attention_heads))\n",
    "layer_head_mask = np.random.randn(encoder_attention_heads)\n",
    "\n",
    "ms_hidden_states = mindspore.Tensor(hidden_states, dtype=mindspore.float32)\n",
    "ms_input_ids = mindspore.Tensor(input_ids, dtype=mindspore.int64)\n",
    "ms_attention_mask = mindspore.Tensor(attention_mask, dtype=mindspore.float32)\n",
    "ms_head_mask = mindspore.Tensor(head_mask, dtype=mindspore.bool_)\n",
    "ms_layer_head_mask = mindspore.Tensor(layer_head_mask, dtype=mindspore.float32)\n",
    "\n",
    "pt_hidden_states = torch.tensor(hidden_states, dtype=torch.float)\n",
    "pt_input_ids = torch.tensor(input_ids, dtype=torch.long)\n",
    "pt_attention_mask = torch.tensor(attention_mask, dtype=torch.float)\n",
    "pt_head_mask = torch.tensor(head_mask, dtype=torch.bool)\n",
    "pt_layer_head_mask = torch.tensor(layer_head_mask, dtype=torch.float)\n",
    "\n",
    "# 记录pt参数中所有的key, 若ms中存在, 则从key中抹去\n",
    "pt_param_keys = set(pt_model.state_dict().keys())\n",
    "\n",
    "ms_notfound_keys = set()\n",
    "# 记录ms中无法在pt中找到的参数\n",
    "# for key, param in ms_model.parameters_and_names():\n",
    "#     if key in pt_param_keys:\n",
    "#         pt_param_keys.remove(key)\n",
    "#     else:\n",
    "#         ms_notfound_keys.add(key)\n",
    "\n",
    "# print(\"pt中未使用参数\",pt_param_keys)\n",
    "# print(\"ms中未找到参数\",ms_notfound_keys)\n",
    "\n",
    "for key, param in ms_model.parameters_and_names():\n",
    "    # 预处理key\n",
    "    key = key.replace('gamma','weight')\n",
    "    key = key.replace('beta','bias')\n",
    "    key = key.replace('embedding_table','weight')\n",
    "    param.set_data(mindspore.Tensor(pt_model.state_dict().get(key).detach().numpy()))\n",
    "\n",
    "ms_model.set_train(False)\n",
    "pt_model.eval()\n",
    "\n",
    "ms_out = ms_model(ms_input_ids)\n",
    "pt_out = pt_model(pt_input_ids)\n",
    "\n",
    "def judge(o1, o2, loss = 1e-5, prefix = '-'):\n",
    "    prefix += '-'\n",
    "    if (isinstance(o1, tuple)):\n",
    "        assert len(o1) == len(o2)\n",
    "        for i in range(len(o1)):\n",
    "            judge(o1[i], o2[i], loss=loss, prefix=prefix)\n",
    "    elif (isinstance(o1,mindspore.Tensor)):\n",
    "        assert o1.shape == o2.shape\n",
    "        print(f\"{prefix}{np.allclose(o1.asnumpy(), o2.detach().numpy(), loss, loss)}\")\n",
    "    else:\n",
    "        print(f\"{type(o1)}-{type(o2)}:{o1==o2}\")\n",
    "\n",
    "judge(ms_out,pt_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--True\n"
     ]
    }
   ],
   "source": [
    "import mindspore\n",
    "from mindspore import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def test_me():\n",
    "    input_x = mindspore.Tensor(np.array([[-1.0, 4.0, -8.0], [2.0, -5.0, 9.0]]), mindspore.float32)\n",
    "    fast_gelu = nn.GELU(approximate=False)\n",
    "    output = fast_gelu(input_x)\n",
    "    return output\n",
    "\n",
    "def test_torch():\n",
    "    input_x = torch.Tensor(np.array([[-1.0, 4.0, -8.0], [2.0, -5.0, 9.0]]))\n",
    "    gelu = torch.nn.GELU()\n",
    "    output = gelu(input_x)\n",
    "    return output\n",
    "\n",
    "def judge(o1, o2, loss = 1e-5, prefix = '-'):\n",
    "    prefix += '-'\n",
    "    if (isinstance(o1, tuple)):\n",
    "        assert len(o1) == len(o2)\n",
    "        for i in range(len(o1)):\n",
    "            judge(o1[i], o2[i], loss=loss, prefix=prefix)\n",
    "    elif (isinstance(o1,mindspore.Tensor)):\n",
    "        assert o1.shape == o2.shape\n",
    "        print(f\"{prefix}{np.allclose(o1.asnumpy(), o2.detach().numpy(), loss, loss)}\")\n",
    "    else:\n",
    "        print(f\"{type(o1)}-{type(o2)}:{o1==o2}\")\n",
    "\n",
    "ms_out = test_me()\n",
    "pt_out = test_torch()\n",
    "\n",
    "judge(ms_out,pt_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--True\n"
     ]
    }
   ],
   "source": [
    "import mindspore\n",
    "from mindspore import nn\n",
    "from transformers.activations import NewGELUActivation\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "def test_me():\n",
    "    input_x = mindspore.Tensor(np.array([[-1.0, 4.0, -8.0], [2.0, -5.0, 9.0]]), mindspore.float32)\n",
    "    fast_gelu = nn.GELU(approximate=True)\n",
    "    output = fast_gelu(input_x)\n",
    "    return output\n",
    "\n",
    "def test_torch():\n",
    "    input_x = torch.Tensor(np.array([[-1.0, 4.0, -8.0], [2.0, -5.0, 9.0]]))\n",
    "    gelu = NewGELUActivation()\n",
    "    output = gelu(input_x)\n",
    "    return output\n",
    "\n",
    "def judge(o1, o2, loss = 1e-5, prefix = '-'):\n",
    "    prefix += '-'\n",
    "    if (isinstance(o1, tuple)):\n",
    "        assert len(o1) == len(o2)\n",
    "        for i in range(len(o1)):\n",
    "            judge(o1[i], o2[i], loss=loss, prefix=prefix)\n",
    "    elif (isinstance(o1,mindspore.Tensor)):\n",
    "        assert o1.shape == o2.shape\n",
    "        print(f\"{prefix}{np.allclose(o1.asnumpy(), o2.detach().numpy(), loss, loss)}\")\n",
    "    else:\n",
    "        print(f\"{type(o1)}-{type(o2)}:{o1==o2}\")\n",
    "\n",
    "ms_out = test_me()\n",
    "pt_out = test_torch()\n",
    "\n",
    "judge(ms_out,pt_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wget https://huggingface.co/facebook/bart-large-xsum/resolve/main/config.json -P /home/wangxingran/bart_migration/Bartckpt/facebook/bart-large-xsum\n",
      "wget https://huggingface.co/facebook/bart-large-xsum/resolve/main/tokenizer.json -P /home/wangxingran/bart_migration/Bartckpt/facebook/bart-large-xsum\n",
      "wget https://huggingface.co/facebook/bart-large-xsum/resolve/main/pytorch_model.bin -P /home/wangxingran/bart_migration/Bartckpt/facebook/bart-large-xsum\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_url\n",
    "\n",
    "path = \"/home/wangxingran/bart_migration/Bartckpt\"\n",
    "\n",
    "def download_script(size:str):\n",
    "    \"\"\"print wget to download files of a pretrained model\"\"\"\n",
    "    print(f\"wget {hf_hub_url(repo_id=size, filename='config.json')} -P {path}/{size}\")\n",
    "    print(f\"wget {hf_hub_url(repo_id=size, filename='tokenizer.json')} -P {path}/{size}\")\n",
    "    print(f\"wget {hf_hub_url(repo_id=size, filename='pytorch_model.bin')} -P {path}/{size}\")\n",
    "\n",
    "sizes = [\"facebook/bart-base\", \"facebook/bart-large\", \"facebook/bart-large-mnli\", \"facebook/bart-large-cnn\", \"facebook/bart-large-xsum\"]\n",
    "\n",
    "download_script(sizes[4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mindspore_py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
