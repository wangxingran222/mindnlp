{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangxingran/anaconda3/envs/mindspore_py37/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch, mindspore\n",
    "import numpy as np\n",
    "from transformers.models.bart import modeling_bart as pt\n",
    "import mindnlp.models.bart as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"/home/wangxingran/bart_migration/Bartckpt/facebook/bart-large-xsum\"\n",
    "config_path = f\"{path}/config.json\"\n",
    "pytorch_model_path = f\"{path}/pytorch_model.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['final_logits_bias', 'lm_head.weight'], unexpected_keys=[])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init config\n",
    "import json\n",
    "with open(config_path, encoding='utf-8') as config:\n",
    "    config = json.load(config)\n",
    "\n",
    "pt_config = pt.BartConfig(**config)\n",
    "pt_dict = torch.load(pytorch_model_path)\n",
    "pt_model = pt.BartForConditionalGeneration(pt_config)\n",
    "pt_model.load_state_dict(pt_dict, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_logits_bias\n",
      "model.shared.weight\n",
      "model.encoder.embed_tokens.weight\n",
      "model.encoder.embed_positions.weight\n",
      "model.encoder.layers.0.self_attn.k_proj.weight\n",
      "model.encoder.layers.0.self_attn.k_proj.bias\n",
      "model.encoder.layers.0.self_attn.v_proj.weight\n",
      "model.encoder.layers.0.self_attn.v_proj.bias\n",
      "model.encoder.layers.0.self_attn.q_proj.weight\n",
      "model.encoder.layers.0.self_attn.q_proj.bias\n",
      "model.encoder.layers.0.self_attn.out_proj.weight\n",
      "model.encoder.layers.0.self_attn.out_proj.bias\n",
      "model.encoder.layers.0.self_attn_layer_norm.weight\n",
      "model.encoder.layers.0.self_attn_layer_norm.bias\n",
      "model.encoder.layers.0.fc1.weight\n",
      "model.encoder.layers.0.fc1.bias\n",
      "model.encoder.layers.0.fc2.weight\n",
      "model.encoder.layers.0.fc2.bias\n",
      "model.encoder.layers.0.final_layer_norm.weight\n",
      "model.encoder.layers.0.final_layer_norm.bias\n",
      "model.encoder.layers.1.self_attn.k_proj.weight\n",
      "model.encoder.layers.1.self_attn.k_proj.bias\n",
      "model.encoder.layers.1.self_attn.v_proj.weight\n",
      "model.encoder.layers.1.self_attn.v_proj.bias\n",
      "model.encoder.layers.1.self_attn.q_proj.weight\n",
      "model.encoder.layers.1.self_attn.q_proj.bias\n",
      "model.encoder.layers.1.self_attn.out_proj.weight\n",
      "model.encoder.layers.1.self_attn.out_proj.bias\n",
      "model.encoder.layers.1.self_attn_layer_norm.weight\n",
      "model.encoder.layers.1.self_attn_layer_norm.bias\n",
      "model.encoder.layers.1.fc1.weight\n",
      "model.encoder.layers.1.fc1.bias\n",
      "model.encoder.layers.1.fc2.weight\n",
      "model.encoder.layers.1.fc2.bias\n",
      "model.encoder.layers.1.final_layer_norm.weight\n",
      "model.encoder.layers.1.final_layer_norm.bias\n",
      "model.encoder.layers.2.self_attn.k_proj.weight\n",
      "model.encoder.layers.2.self_attn.k_proj.bias\n",
      "model.encoder.layers.2.self_attn.v_proj.weight\n",
      "model.encoder.layers.2.self_attn.v_proj.bias\n",
      "model.encoder.layers.2.self_attn.q_proj.weight\n",
      "model.encoder.layers.2.self_attn.q_proj.bias\n",
      "model.encoder.layers.2.self_attn.out_proj.weight\n",
      "model.encoder.layers.2.self_attn.out_proj.bias\n",
      "model.encoder.layers.2.self_attn_layer_norm.weight\n",
      "model.encoder.layers.2.self_attn_layer_norm.bias\n",
      "model.encoder.layers.2.fc1.weight\n",
      "model.encoder.layers.2.fc1.bias\n",
      "model.encoder.layers.2.fc2.weight\n",
      "model.encoder.layers.2.fc2.bias\n",
      "model.encoder.layers.2.final_layer_norm.weight\n",
      "model.encoder.layers.2.final_layer_norm.bias\n",
      "model.encoder.layers.3.self_attn.k_proj.weight\n",
      "model.encoder.layers.3.self_attn.k_proj.bias\n",
      "model.encoder.layers.3.self_attn.v_proj.weight\n",
      "model.encoder.layers.3.self_attn.v_proj.bias\n",
      "model.encoder.layers.3.self_attn.q_proj.weight\n",
      "model.encoder.layers.3.self_attn.q_proj.bias\n",
      "model.encoder.layers.3.self_attn.out_proj.weight\n",
      "model.encoder.layers.3.self_attn.out_proj.bias\n",
      "model.encoder.layers.3.self_attn_layer_norm.weight\n",
      "model.encoder.layers.3.self_attn_layer_norm.bias\n",
      "model.encoder.layers.3.fc1.weight\n",
      "model.encoder.layers.3.fc1.bias\n",
      "model.encoder.layers.3.fc2.weight\n",
      "model.encoder.layers.3.fc2.bias\n",
      "model.encoder.layers.3.final_layer_norm.weight\n",
      "model.encoder.layers.3.final_layer_norm.bias\n",
      "model.encoder.layers.4.self_attn.k_proj.weight\n",
      "model.encoder.layers.4.self_attn.k_proj.bias\n",
      "model.encoder.layers.4.self_attn.v_proj.weight\n",
      "model.encoder.layers.4.self_attn.v_proj.bias\n",
      "model.encoder.layers.4.self_attn.q_proj.weight\n",
      "model.encoder.layers.4.self_attn.q_proj.bias\n",
      "model.encoder.layers.4.self_attn.out_proj.weight\n",
      "model.encoder.layers.4.self_attn.out_proj.bias\n",
      "model.encoder.layers.4.self_attn_layer_norm.weight\n",
      "model.encoder.layers.4.self_attn_layer_norm.bias\n",
      "model.encoder.layers.4.fc1.weight\n",
      "model.encoder.layers.4.fc1.bias\n",
      "model.encoder.layers.4.fc2.weight\n",
      "model.encoder.layers.4.fc2.bias\n",
      "model.encoder.layers.4.final_layer_norm.weight\n",
      "model.encoder.layers.4.final_layer_norm.bias\n",
      "model.encoder.layers.5.self_attn.k_proj.weight\n",
      "model.encoder.layers.5.self_attn.k_proj.bias\n",
      "model.encoder.layers.5.self_attn.v_proj.weight\n",
      "model.encoder.layers.5.self_attn.v_proj.bias\n",
      "model.encoder.layers.5.self_attn.q_proj.weight\n",
      "model.encoder.layers.5.self_attn.q_proj.bias\n",
      "model.encoder.layers.5.self_attn.out_proj.weight\n",
      "model.encoder.layers.5.self_attn.out_proj.bias\n",
      "model.encoder.layers.5.self_attn_layer_norm.weight\n",
      "model.encoder.layers.5.self_attn_layer_norm.bias\n",
      "model.encoder.layers.5.fc1.weight\n",
      "model.encoder.layers.5.fc1.bias\n",
      "model.encoder.layers.5.fc2.weight\n",
      "model.encoder.layers.5.fc2.bias\n",
      "model.encoder.layers.5.final_layer_norm.weight\n",
      "model.encoder.layers.5.final_layer_norm.bias\n",
      "model.encoder.layers.6.self_attn.k_proj.weight\n",
      "model.encoder.layers.6.self_attn.k_proj.bias\n",
      "model.encoder.layers.6.self_attn.v_proj.weight\n",
      "model.encoder.layers.6.self_attn.v_proj.bias\n",
      "model.encoder.layers.6.self_attn.q_proj.weight\n",
      "model.encoder.layers.6.self_attn.q_proj.bias\n",
      "model.encoder.layers.6.self_attn.out_proj.weight\n",
      "model.encoder.layers.6.self_attn.out_proj.bias\n",
      "model.encoder.layers.6.self_attn_layer_norm.weight\n",
      "model.encoder.layers.6.self_attn_layer_norm.bias\n",
      "model.encoder.layers.6.fc1.weight\n",
      "model.encoder.layers.6.fc1.bias\n",
      "model.encoder.layers.6.fc2.weight\n",
      "model.encoder.layers.6.fc2.bias\n",
      "model.encoder.layers.6.final_layer_norm.weight\n",
      "model.encoder.layers.6.final_layer_norm.bias\n",
      "model.encoder.layers.7.self_attn.k_proj.weight\n",
      "model.encoder.layers.7.self_attn.k_proj.bias\n",
      "model.encoder.layers.7.self_attn.v_proj.weight\n",
      "model.encoder.layers.7.self_attn.v_proj.bias\n",
      "model.encoder.layers.7.self_attn.q_proj.weight\n",
      "model.encoder.layers.7.self_attn.q_proj.bias\n",
      "model.encoder.layers.7.self_attn.out_proj.weight\n",
      "model.encoder.layers.7.self_attn.out_proj.bias\n",
      "model.encoder.layers.7.self_attn_layer_norm.weight\n",
      "model.encoder.layers.7.self_attn_layer_norm.bias\n",
      "model.encoder.layers.7.fc1.weight\n",
      "model.encoder.layers.7.fc1.bias\n",
      "model.encoder.layers.7.fc2.weight\n",
      "model.encoder.layers.7.fc2.bias\n",
      "model.encoder.layers.7.final_layer_norm.weight\n",
      "model.encoder.layers.7.final_layer_norm.bias\n",
      "model.encoder.layers.8.self_attn.k_proj.weight\n",
      "model.encoder.layers.8.self_attn.k_proj.bias\n",
      "model.encoder.layers.8.self_attn.v_proj.weight\n",
      "model.encoder.layers.8.self_attn.v_proj.bias\n",
      "model.encoder.layers.8.self_attn.q_proj.weight\n",
      "model.encoder.layers.8.self_attn.q_proj.bias\n",
      "model.encoder.layers.8.self_attn.out_proj.weight\n",
      "model.encoder.layers.8.self_attn.out_proj.bias\n",
      "model.encoder.layers.8.self_attn_layer_norm.weight\n",
      "model.encoder.layers.8.self_attn_layer_norm.bias\n",
      "model.encoder.layers.8.fc1.weight\n",
      "model.encoder.layers.8.fc1.bias\n",
      "model.encoder.layers.8.fc2.weight\n",
      "model.encoder.layers.8.fc2.bias\n",
      "model.encoder.layers.8.final_layer_norm.weight\n",
      "model.encoder.layers.8.final_layer_norm.bias\n",
      "model.encoder.layers.9.self_attn.k_proj.weight\n",
      "model.encoder.layers.9.self_attn.k_proj.bias\n",
      "model.encoder.layers.9.self_attn.v_proj.weight\n",
      "model.encoder.layers.9.self_attn.v_proj.bias\n",
      "model.encoder.layers.9.self_attn.q_proj.weight\n",
      "model.encoder.layers.9.self_attn.q_proj.bias\n",
      "model.encoder.layers.9.self_attn.out_proj.weight\n",
      "model.encoder.layers.9.self_attn.out_proj.bias\n",
      "model.encoder.layers.9.self_attn_layer_norm.weight\n",
      "model.encoder.layers.9.self_attn_layer_norm.bias\n",
      "model.encoder.layers.9.fc1.weight\n",
      "model.encoder.layers.9.fc1.bias\n",
      "model.encoder.layers.9.fc2.weight\n",
      "model.encoder.layers.9.fc2.bias\n",
      "model.encoder.layers.9.final_layer_norm.weight\n",
      "model.encoder.layers.9.final_layer_norm.bias\n",
      "model.encoder.layers.10.self_attn.k_proj.weight\n",
      "model.encoder.layers.10.self_attn.k_proj.bias\n",
      "model.encoder.layers.10.self_attn.v_proj.weight\n",
      "model.encoder.layers.10.self_attn.v_proj.bias\n",
      "model.encoder.layers.10.self_attn.q_proj.weight\n",
      "model.encoder.layers.10.self_attn.q_proj.bias\n",
      "model.encoder.layers.10.self_attn.out_proj.weight\n",
      "model.encoder.layers.10.self_attn.out_proj.bias\n",
      "model.encoder.layers.10.self_attn_layer_norm.weight\n",
      "model.encoder.layers.10.self_attn_layer_norm.bias\n",
      "model.encoder.layers.10.fc1.weight\n",
      "model.encoder.layers.10.fc1.bias\n",
      "model.encoder.layers.10.fc2.weight\n",
      "model.encoder.layers.10.fc2.bias\n",
      "model.encoder.layers.10.final_layer_norm.weight\n",
      "model.encoder.layers.10.final_layer_norm.bias\n",
      "model.encoder.layers.11.self_attn.k_proj.weight\n",
      "model.encoder.layers.11.self_attn.k_proj.bias\n",
      "model.encoder.layers.11.self_attn.v_proj.weight\n",
      "model.encoder.layers.11.self_attn.v_proj.bias\n",
      "model.encoder.layers.11.self_attn.q_proj.weight\n",
      "model.encoder.layers.11.self_attn.q_proj.bias\n",
      "model.encoder.layers.11.self_attn.out_proj.weight\n",
      "model.encoder.layers.11.self_attn.out_proj.bias\n",
      "model.encoder.layers.11.self_attn_layer_norm.weight\n",
      "model.encoder.layers.11.self_attn_layer_norm.bias\n",
      "model.encoder.layers.11.fc1.weight\n",
      "model.encoder.layers.11.fc1.bias\n",
      "model.encoder.layers.11.fc2.weight\n",
      "model.encoder.layers.11.fc2.bias\n",
      "model.encoder.layers.11.final_layer_norm.weight\n",
      "model.encoder.layers.11.final_layer_norm.bias\n",
      "model.encoder.layernorm_embedding.weight\n",
      "model.encoder.layernorm_embedding.bias\n",
      "model.decoder.embed_tokens.weight\n",
      "model.decoder.embed_positions.weight\n",
      "model.decoder.layers.0.self_attn.k_proj.weight\n",
      "model.decoder.layers.0.self_attn.k_proj.bias\n",
      "model.decoder.layers.0.self_attn.v_proj.weight\n",
      "model.decoder.layers.0.self_attn.v_proj.bias\n",
      "model.decoder.layers.0.self_attn.q_proj.weight\n",
      "model.decoder.layers.0.self_attn.q_proj.bias\n",
      "model.decoder.layers.0.self_attn.out_proj.weight\n",
      "model.decoder.layers.0.self_attn.out_proj.bias\n",
      "model.decoder.layers.0.self_attn_layer_norm.weight\n",
      "model.decoder.layers.0.self_attn_layer_norm.bias\n",
      "model.decoder.layers.0.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.0.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.0.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.0.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.0.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.0.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.0.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.0.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.0.encoder_attn_layer_norm.weight\n",
      "model.decoder.layers.0.encoder_attn_layer_norm.bias\n",
      "model.decoder.layers.0.fc1.weight\n",
      "model.decoder.layers.0.fc1.bias\n",
      "model.decoder.layers.0.fc2.weight\n",
      "model.decoder.layers.0.fc2.bias\n",
      "model.decoder.layers.0.final_layer_norm.weight\n",
      "model.decoder.layers.0.final_layer_norm.bias\n",
      "model.decoder.layers.1.self_attn.k_proj.weight\n",
      "model.decoder.layers.1.self_attn.k_proj.bias\n",
      "model.decoder.layers.1.self_attn.v_proj.weight\n",
      "model.decoder.layers.1.self_attn.v_proj.bias\n",
      "model.decoder.layers.1.self_attn.q_proj.weight\n",
      "model.decoder.layers.1.self_attn.q_proj.bias\n",
      "model.decoder.layers.1.self_attn.out_proj.weight\n",
      "model.decoder.layers.1.self_attn.out_proj.bias\n",
      "model.decoder.layers.1.self_attn_layer_norm.weight\n",
      "model.decoder.layers.1.self_attn_layer_norm.bias\n",
      "model.decoder.layers.1.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.1.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.1.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.1.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.1.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.1.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.1.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.1.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.1.encoder_attn_layer_norm.weight\n",
      "model.decoder.layers.1.encoder_attn_layer_norm.bias\n",
      "model.decoder.layers.1.fc1.weight\n",
      "model.decoder.layers.1.fc1.bias\n",
      "model.decoder.layers.1.fc2.weight\n",
      "model.decoder.layers.1.fc2.bias\n",
      "model.decoder.layers.1.final_layer_norm.weight\n",
      "model.decoder.layers.1.final_layer_norm.bias\n",
      "model.decoder.layers.2.self_attn.k_proj.weight\n",
      "model.decoder.layers.2.self_attn.k_proj.bias\n",
      "model.decoder.layers.2.self_attn.v_proj.weight\n",
      "model.decoder.layers.2.self_attn.v_proj.bias\n",
      "model.decoder.layers.2.self_attn.q_proj.weight\n",
      "model.decoder.layers.2.self_attn.q_proj.bias\n",
      "model.decoder.layers.2.self_attn.out_proj.weight\n",
      "model.decoder.layers.2.self_attn.out_proj.bias\n",
      "model.decoder.layers.2.self_attn_layer_norm.weight\n",
      "model.decoder.layers.2.self_attn_layer_norm.bias\n",
      "model.decoder.layers.2.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.2.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.2.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.2.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.2.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.2.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.2.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.2.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.2.encoder_attn_layer_norm.weight\n",
      "model.decoder.layers.2.encoder_attn_layer_norm.bias\n",
      "model.decoder.layers.2.fc1.weight\n",
      "model.decoder.layers.2.fc1.bias\n",
      "model.decoder.layers.2.fc2.weight\n",
      "model.decoder.layers.2.fc2.bias\n",
      "model.decoder.layers.2.final_layer_norm.weight\n",
      "model.decoder.layers.2.final_layer_norm.bias\n",
      "model.decoder.layers.3.self_attn.k_proj.weight\n",
      "model.decoder.layers.3.self_attn.k_proj.bias\n",
      "model.decoder.layers.3.self_attn.v_proj.weight\n",
      "model.decoder.layers.3.self_attn.v_proj.bias\n",
      "model.decoder.layers.3.self_attn.q_proj.weight\n",
      "model.decoder.layers.3.self_attn.q_proj.bias\n",
      "model.decoder.layers.3.self_attn.out_proj.weight\n",
      "model.decoder.layers.3.self_attn.out_proj.bias\n",
      "model.decoder.layers.3.self_attn_layer_norm.weight\n",
      "model.decoder.layers.3.self_attn_layer_norm.bias\n",
      "model.decoder.layers.3.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.3.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.3.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.3.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.3.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.3.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.3.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.3.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.3.encoder_attn_layer_norm.weight\n",
      "model.decoder.layers.3.encoder_attn_layer_norm.bias\n",
      "model.decoder.layers.3.fc1.weight\n",
      "model.decoder.layers.3.fc1.bias\n",
      "model.decoder.layers.3.fc2.weight\n",
      "model.decoder.layers.3.fc2.bias\n",
      "model.decoder.layers.3.final_layer_norm.weight\n",
      "model.decoder.layers.3.final_layer_norm.bias\n",
      "model.decoder.layers.4.self_attn.k_proj.weight\n",
      "model.decoder.layers.4.self_attn.k_proj.bias\n",
      "model.decoder.layers.4.self_attn.v_proj.weight\n",
      "model.decoder.layers.4.self_attn.v_proj.bias\n",
      "model.decoder.layers.4.self_attn.q_proj.weight\n",
      "model.decoder.layers.4.self_attn.q_proj.bias\n",
      "model.decoder.layers.4.self_attn.out_proj.weight\n",
      "model.decoder.layers.4.self_attn.out_proj.bias\n",
      "model.decoder.layers.4.self_attn_layer_norm.weight\n",
      "model.decoder.layers.4.self_attn_layer_norm.bias\n",
      "model.decoder.layers.4.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.4.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.4.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.4.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.4.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.4.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.4.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.4.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.4.encoder_attn_layer_norm.weight\n",
      "model.decoder.layers.4.encoder_attn_layer_norm.bias\n",
      "model.decoder.layers.4.fc1.weight\n",
      "model.decoder.layers.4.fc1.bias\n",
      "model.decoder.layers.4.fc2.weight\n",
      "model.decoder.layers.4.fc2.bias\n",
      "model.decoder.layers.4.final_layer_norm.weight\n",
      "model.decoder.layers.4.final_layer_norm.bias\n",
      "model.decoder.layers.5.self_attn.k_proj.weight\n",
      "model.decoder.layers.5.self_attn.k_proj.bias\n",
      "model.decoder.layers.5.self_attn.v_proj.weight\n",
      "model.decoder.layers.5.self_attn.v_proj.bias\n",
      "model.decoder.layers.5.self_attn.q_proj.weight\n",
      "model.decoder.layers.5.self_attn.q_proj.bias\n",
      "model.decoder.layers.5.self_attn.out_proj.weight\n",
      "model.decoder.layers.5.self_attn.out_proj.bias\n",
      "model.decoder.layers.5.self_attn_layer_norm.weight\n",
      "model.decoder.layers.5.self_attn_layer_norm.bias\n",
      "model.decoder.layers.5.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.5.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.5.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.5.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.5.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.5.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.5.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.5.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.5.encoder_attn_layer_norm.weight\n",
      "model.decoder.layers.5.encoder_attn_layer_norm.bias\n",
      "model.decoder.layers.5.fc1.weight\n",
      "model.decoder.layers.5.fc1.bias\n",
      "model.decoder.layers.5.fc2.weight\n",
      "model.decoder.layers.5.fc2.bias\n",
      "model.decoder.layers.5.final_layer_norm.weight\n",
      "model.decoder.layers.5.final_layer_norm.bias\n",
      "model.decoder.layers.6.self_attn.k_proj.weight\n",
      "model.decoder.layers.6.self_attn.k_proj.bias\n",
      "model.decoder.layers.6.self_attn.v_proj.weight\n",
      "model.decoder.layers.6.self_attn.v_proj.bias\n",
      "model.decoder.layers.6.self_attn.q_proj.weight\n",
      "model.decoder.layers.6.self_attn.q_proj.bias\n",
      "model.decoder.layers.6.self_attn.out_proj.weight\n",
      "model.decoder.layers.6.self_attn.out_proj.bias\n",
      "model.decoder.layers.6.self_attn_layer_norm.weight\n",
      "model.decoder.layers.6.self_attn_layer_norm.bias\n",
      "model.decoder.layers.6.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.6.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.6.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.6.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.6.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.6.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.6.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.6.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.6.encoder_attn_layer_norm.weight\n",
      "model.decoder.layers.6.encoder_attn_layer_norm.bias\n",
      "model.decoder.layers.6.fc1.weight\n",
      "model.decoder.layers.6.fc1.bias\n",
      "model.decoder.layers.6.fc2.weight\n",
      "model.decoder.layers.6.fc2.bias\n",
      "model.decoder.layers.6.final_layer_norm.weight\n",
      "model.decoder.layers.6.final_layer_norm.bias\n",
      "model.decoder.layers.7.self_attn.k_proj.weight\n",
      "model.decoder.layers.7.self_attn.k_proj.bias\n",
      "model.decoder.layers.7.self_attn.v_proj.weight\n",
      "model.decoder.layers.7.self_attn.v_proj.bias\n",
      "model.decoder.layers.7.self_attn.q_proj.weight\n",
      "model.decoder.layers.7.self_attn.q_proj.bias\n",
      "model.decoder.layers.7.self_attn.out_proj.weight\n",
      "model.decoder.layers.7.self_attn.out_proj.bias\n",
      "model.decoder.layers.7.self_attn_layer_norm.weight\n",
      "model.decoder.layers.7.self_attn_layer_norm.bias\n",
      "model.decoder.layers.7.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.7.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.7.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.7.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.7.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.7.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.7.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.7.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.7.encoder_attn_layer_norm.weight\n",
      "model.decoder.layers.7.encoder_attn_layer_norm.bias\n",
      "model.decoder.layers.7.fc1.weight\n",
      "model.decoder.layers.7.fc1.bias\n",
      "model.decoder.layers.7.fc2.weight\n",
      "model.decoder.layers.7.fc2.bias\n",
      "model.decoder.layers.7.final_layer_norm.weight\n",
      "model.decoder.layers.7.final_layer_norm.bias\n",
      "model.decoder.layers.8.self_attn.k_proj.weight\n",
      "model.decoder.layers.8.self_attn.k_proj.bias\n",
      "model.decoder.layers.8.self_attn.v_proj.weight\n",
      "model.decoder.layers.8.self_attn.v_proj.bias\n",
      "model.decoder.layers.8.self_attn.q_proj.weight\n",
      "model.decoder.layers.8.self_attn.q_proj.bias\n",
      "model.decoder.layers.8.self_attn.out_proj.weight\n",
      "model.decoder.layers.8.self_attn.out_proj.bias\n",
      "model.decoder.layers.8.self_attn_layer_norm.weight\n",
      "model.decoder.layers.8.self_attn_layer_norm.bias\n",
      "model.decoder.layers.8.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.8.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.8.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.8.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.8.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.8.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.8.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.8.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.8.encoder_attn_layer_norm.weight\n",
      "model.decoder.layers.8.encoder_attn_layer_norm.bias\n",
      "model.decoder.layers.8.fc1.weight\n",
      "model.decoder.layers.8.fc1.bias\n",
      "model.decoder.layers.8.fc2.weight\n",
      "model.decoder.layers.8.fc2.bias\n",
      "model.decoder.layers.8.final_layer_norm.weight\n",
      "model.decoder.layers.8.final_layer_norm.bias\n",
      "model.decoder.layers.9.self_attn.k_proj.weight\n",
      "model.decoder.layers.9.self_attn.k_proj.bias\n",
      "model.decoder.layers.9.self_attn.v_proj.weight\n",
      "model.decoder.layers.9.self_attn.v_proj.bias\n",
      "model.decoder.layers.9.self_attn.q_proj.weight\n",
      "model.decoder.layers.9.self_attn.q_proj.bias\n",
      "model.decoder.layers.9.self_attn.out_proj.weight\n",
      "model.decoder.layers.9.self_attn.out_proj.bias\n",
      "model.decoder.layers.9.self_attn_layer_norm.weight\n",
      "model.decoder.layers.9.self_attn_layer_norm.bias\n",
      "model.decoder.layers.9.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.9.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.9.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.9.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.9.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.9.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.9.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.9.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.9.encoder_attn_layer_norm.weight\n",
      "model.decoder.layers.9.encoder_attn_layer_norm.bias\n",
      "model.decoder.layers.9.fc1.weight\n",
      "model.decoder.layers.9.fc1.bias\n",
      "model.decoder.layers.9.fc2.weight\n",
      "model.decoder.layers.9.fc2.bias\n",
      "model.decoder.layers.9.final_layer_norm.weight\n",
      "model.decoder.layers.9.final_layer_norm.bias\n",
      "model.decoder.layers.10.self_attn.k_proj.weight\n",
      "model.decoder.layers.10.self_attn.k_proj.bias\n",
      "model.decoder.layers.10.self_attn.v_proj.weight\n",
      "model.decoder.layers.10.self_attn.v_proj.bias\n",
      "model.decoder.layers.10.self_attn.q_proj.weight\n",
      "model.decoder.layers.10.self_attn.q_proj.bias\n",
      "model.decoder.layers.10.self_attn.out_proj.weight\n",
      "model.decoder.layers.10.self_attn.out_proj.bias\n",
      "model.decoder.layers.10.self_attn_layer_norm.weight\n",
      "model.decoder.layers.10.self_attn_layer_norm.bias\n",
      "model.decoder.layers.10.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.10.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.10.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.10.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.10.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.10.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.10.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.10.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.10.encoder_attn_layer_norm.weight\n",
      "model.decoder.layers.10.encoder_attn_layer_norm.bias\n",
      "model.decoder.layers.10.fc1.weight\n",
      "model.decoder.layers.10.fc1.bias\n",
      "model.decoder.layers.10.fc2.weight\n",
      "model.decoder.layers.10.fc2.bias\n",
      "model.decoder.layers.10.final_layer_norm.weight\n",
      "model.decoder.layers.10.final_layer_norm.bias\n",
      "model.decoder.layers.11.self_attn.k_proj.weight\n",
      "model.decoder.layers.11.self_attn.k_proj.bias\n",
      "model.decoder.layers.11.self_attn.v_proj.weight\n",
      "model.decoder.layers.11.self_attn.v_proj.bias\n",
      "model.decoder.layers.11.self_attn.q_proj.weight\n",
      "model.decoder.layers.11.self_attn.q_proj.bias\n",
      "model.decoder.layers.11.self_attn.out_proj.weight\n",
      "model.decoder.layers.11.self_attn.out_proj.bias\n",
      "model.decoder.layers.11.self_attn_layer_norm.weight\n",
      "model.decoder.layers.11.self_attn_layer_norm.bias\n",
      "model.decoder.layers.11.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.11.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.11.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.11.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.11.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.11.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.11.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.11.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.11.encoder_attn_layer_norm.weight\n",
      "model.decoder.layers.11.encoder_attn_layer_norm.bias\n",
      "model.decoder.layers.11.fc1.weight\n",
      "model.decoder.layers.11.fc1.bias\n",
      "model.decoder.layers.11.fc2.weight\n",
      "model.decoder.layers.11.fc2.bias\n",
      "model.decoder.layers.11.final_layer_norm.weight\n",
      "model.decoder.layers.11.final_layer_norm.bias\n",
      "model.decoder.layernorm_embedding.weight\n",
      "model.decoder.layernorm_embedding.bias\n",
      "lm_head.weight\n"
     ]
    }
   ],
   "source": [
    "pt_params = pt_model.state_dict()\n",
    "for key in pt_params.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init config\n",
    "ms_config = m.BartConfig(**config)\n",
    "ms_model = m.BartForConditionalGeneration(ms_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_logits_bias\n",
      "model.shared.embedding_table\n",
      "model.encoder.embed_positions.embedding_table\n",
      "model.encoder.layers.0.self_attn.k_proj.weight\n",
      "model.encoder.layers.0.self_attn.k_proj.bias\n",
      "model.encoder.layers.0.self_attn.v_proj.weight\n",
      "model.encoder.layers.0.self_attn.v_proj.bias\n",
      "model.encoder.layers.0.self_attn.q_proj.weight\n",
      "model.encoder.layers.0.self_attn.q_proj.bias\n",
      "model.encoder.layers.0.self_attn.out_proj.weight\n",
      "model.encoder.layers.0.self_attn.out_proj.bias\n",
      "model.encoder.layers.0.self_attn_layer_norm.gamma\n",
      "model.encoder.layers.0.self_attn_layer_norm.beta\n",
      "model.encoder.layers.0.fc1.weight\n",
      "model.encoder.layers.0.fc1.bias\n",
      "model.encoder.layers.0.fc2.weight\n",
      "model.encoder.layers.0.fc2.bias\n",
      "model.encoder.layers.0.final_layer_norm.gamma\n",
      "model.encoder.layers.0.final_layer_norm.beta\n",
      "model.encoder.layers.1.self_attn.k_proj.weight\n",
      "model.encoder.layers.1.self_attn.k_proj.bias\n",
      "model.encoder.layers.1.self_attn.v_proj.weight\n",
      "model.encoder.layers.1.self_attn.v_proj.bias\n",
      "model.encoder.layers.1.self_attn.q_proj.weight\n",
      "model.encoder.layers.1.self_attn.q_proj.bias\n",
      "model.encoder.layers.1.self_attn.out_proj.weight\n",
      "model.encoder.layers.1.self_attn.out_proj.bias\n",
      "model.encoder.layers.1.self_attn_layer_norm.gamma\n",
      "model.encoder.layers.1.self_attn_layer_norm.beta\n",
      "model.encoder.layers.1.fc1.weight\n",
      "model.encoder.layers.1.fc1.bias\n",
      "model.encoder.layers.1.fc2.weight\n",
      "model.encoder.layers.1.fc2.bias\n",
      "model.encoder.layers.1.final_layer_norm.gamma\n",
      "model.encoder.layers.1.final_layer_norm.beta\n",
      "model.encoder.layers.2.self_attn.k_proj.weight\n",
      "model.encoder.layers.2.self_attn.k_proj.bias\n",
      "model.encoder.layers.2.self_attn.v_proj.weight\n",
      "model.encoder.layers.2.self_attn.v_proj.bias\n",
      "model.encoder.layers.2.self_attn.q_proj.weight\n",
      "model.encoder.layers.2.self_attn.q_proj.bias\n",
      "model.encoder.layers.2.self_attn.out_proj.weight\n",
      "model.encoder.layers.2.self_attn.out_proj.bias\n",
      "model.encoder.layers.2.self_attn_layer_norm.gamma\n",
      "model.encoder.layers.2.self_attn_layer_norm.beta\n",
      "model.encoder.layers.2.fc1.weight\n",
      "model.encoder.layers.2.fc1.bias\n",
      "model.encoder.layers.2.fc2.weight\n",
      "model.encoder.layers.2.fc2.bias\n",
      "model.encoder.layers.2.final_layer_norm.gamma\n",
      "model.encoder.layers.2.final_layer_norm.beta\n",
      "model.encoder.layers.3.self_attn.k_proj.weight\n",
      "model.encoder.layers.3.self_attn.k_proj.bias\n",
      "model.encoder.layers.3.self_attn.v_proj.weight\n",
      "model.encoder.layers.3.self_attn.v_proj.bias\n",
      "model.encoder.layers.3.self_attn.q_proj.weight\n",
      "model.encoder.layers.3.self_attn.q_proj.bias\n",
      "model.encoder.layers.3.self_attn.out_proj.weight\n",
      "model.encoder.layers.3.self_attn.out_proj.bias\n",
      "model.encoder.layers.3.self_attn_layer_norm.gamma\n",
      "model.encoder.layers.3.self_attn_layer_norm.beta\n",
      "model.encoder.layers.3.fc1.weight\n",
      "model.encoder.layers.3.fc1.bias\n",
      "model.encoder.layers.3.fc2.weight\n",
      "model.encoder.layers.3.fc2.bias\n",
      "model.encoder.layers.3.final_layer_norm.gamma\n",
      "model.encoder.layers.3.final_layer_norm.beta\n",
      "model.encoder.layers.4.self_attn.k_proj.weight\n",
      "model.encoder.layers.4.self_attn.k_proj.bias\n",
      "model.encoder.layers.4.self_attn.v_proj.weight\n",
      "model.encoder.layers.4.self_attn.v_proj.bias\n",
      "model.encoder.layers.4.self_attn.q_proj.weight\n",
      "model.encoder.layers.4.self_attn.q_proj.bias\n",
      "model.encoder.layers.4.self_attn.out_proj.weight\n",
      "model.encoder.layers.4.self_attn.out_proj.bias\n",
      "model.encoder.layers.4.self_attn_layer_norm.gamma\n",
      "model.encoder.layers.4.self_attn_layer_norm.beta\n",
      "model.encoder.layers.4.fc1.weight\n",
      "model.encoder.layers.4.fc1.bias\n",
      "model.encoder.layers.4.fc2.weight\n",
      "model.encoder.layers.4.fc2.bias\n",
      "model.encoder.layers.4.final_layer_norm.gamma\n",
      "model.encoder.layers.4.final_layer_norm.beta\n",
      "model.encoder.layers.5.self_attn.k_proj.weight\n",
      "model.encoder.layers.5.self_attn.k_proj.bias\n",
      "model.encoder.layers.5.self_attn.v_proj.weight\n",
      "model.encoder.layers.5.self_attn.v_proj.bias\n",
      "model.encoder.layers.5.self_attn.q_proj.weight\n",
      "model.encoder.layers.5.self_attn.q_proj.bias\n",
      "model.encoder.layers.5.self_attn.out_proj.weight\n",
      "model.encoder.layers.5.self_attn.out_proj.bias\n",
      "model.encoder.layers.5.self_attn_layer_norm.gamma\n",
      "model.encoder.layers.5.self_attn_layer_norm.beta\n",
      "model.encoder.layers.5.fc1.weight\n",
      "model.encoder.layers.5.fc1.bias\n",
      "model.encoder.layers.5.fc2.weight\n",
      "model.encoder.layers.5.fc2.bias\n",
      "model.encoder.layers.5.final_layer_norm.gamma\n",
      "model.encoder.layers.5.final_layer_norm.beta\n",
      "model.encoder.layers.6.self_attn.k_proj.weight\n",
      "model.encoder.layers.6.self_attn.k_proj.bias\n",
      "model.encoder.layers.6.self_attn.v_proj.weight\n",
      "model.encoder.layers.6.self_attn.v_proj.bias\n",
      "model.encoder.layers.6.self_attn.q_proj.weight\n",
      "model.encoder.layers.6.self_attn.q_proj.bias\n",
      "model.encoder.layers.6.self_attn.out_proj.weight\n",
      "model.encoder.layers.6.self_attn.out_proj.bias\n",
      "model.encoder.layers.6.self_attn_layer_norm.gamma\n",
      "model.encoder.layers.6.self_attn_layer_norm.beta\n",
      "model.encoder.layers.6.fc1.weight\n",
      "model.encoder.layers.6.fc1.bias\n",
      "model.encoder.layers.6.fc2.weight\n",
      "model.encoder.layers.6.fc2.bias\n",
      "model.encoder.layers.6.final_layer_norm.gamma\n",
      "model.encoder.layers.6.final_layer_norm.beta\n",
      "model.encoder.layers.7.self_attn.k_proj.weight\n",
      "model.encoder.layers.7.self_attn.k_proj.bias\n",
      "model.encoder.layers.7.self_attn.v_proj.weight\n",
      "model.encoder.layers.7.self_attn.v_proj.bias\n",
      "model.encoder.layers.7.self_attn.q_proj.weight\n",
      "model.encoder.layers.7.self_attn.q_proj.bias\n",
      "model.encoder.layers.7.self_attn.out_proj.weight\n",
      "model.encoder.layers.7.self_attn.out_proj.bias\n",
      "model.encoder.layers.7.self_attn_layer_norm.gamma\n",
      "model.encoder.layers.7.self_attn_layer_norm.beta\n",
      "model.encoder.layers.7.fc1.weight\n",
      "model.encoder.layers.7.fc1.bias\n",
      "model.encoder.layers.7.fc2.weight\n",
      "model.encoder.layers.7.fc2.bias\n",
      "model.encoder.layers.7.final_layer_norm.gamma\n",
      "model.encoder.layers.7.final_layer_norm.beta\n",
      "model.encoder.layers.8.self_attn.k_proj.weight\n",
      "model.encoder.layers.8.self_attn.k_proj.bias\n",
      "model.encoder.layers.8.self_attn.v_proj.weight\n",
      "model.encoder.layers.8.self_attn.v_proj.bias\n",
      "model.encoder.layers.8.self_attn.q_proj.weight\n",
      "model.encoder.layers.8.self_attn.q_proj.bias\n",
      "model.encoder.layers.8.self_attn.out_proj.weight\n",
      "model.encoder.layers.8.self_attn.out_proj.bias\n",
      "model.encoder.layers.8.self_attn_layer_norm.gamma\n",
      "model.encoder.layers.8.self_attn_layer_norm.beta\n",
      "model.encoder.layers.8.fc1.weight\n",
      "model.encoder.layers.8.fc1.bias\n",
      "model.encoder.layers.8.fc2.weight\n",
      "model.encoder.layers.8.fc2.bias\n",
      "model.encoder.layers.8.final_layer_norm.gamma\n",
      "model.encoder.layers.8.final_layer_norm.beta\n",
      "model.encoder.layers.9.self_attn.k_proj.weight\n",
      "model.encoder.layers.9.self_attn.k_proj.bias\n",
      "model.encoder.layers.9.self_attn.v_proj.weight\n",
      "model.encoder.layers.9.self_attn.v_proj.bias\n",
      "model.encoder.layers.9.self_attn.q_proj.weight\n",
      "model.encoder.layers.9.self_attn.q_proj.bias\n",
      "model.encoder.layers.9.self_attn.out_proj.weight\n",
      "model.encoder.layers.9.self_attn.out_proj.bias\n",
      "model.encoder.layers.9.self_attn_layer_norm.gamma\n",
      "model.encoder.layers.9.self_attn_layer_norm.beta\n",
      "model.encoder.layers.9.fc1.weight\n",
      "model.encoder.layers.9.fc1.bias\n",
      "model.encoder.layers.9.fc2.weight\n",
      "model.encoder.layers.9.fc2.bias\n",
      "model.encoder.layers.9.final_layer_norm.gamma\n",
      "model.encoder.layers.9.final_layer_norm.beta\n",
      "model.encoder.layers.10.self_attn.k_proj.weight\n",
      "model.encoder.layers.10.self_attn.k_proj.bias\n",
      "model.encoder.layers.10.self_attn.v_proj.weight\n",
      "model.encoder.layers.10.self_attn.v_proj.bias\n",
      "model.encoder.layers.10.self_attn.q_proj.weight\n",
      "model.encoder.layers.10.self_attn.q_proj.bias\n",
      "model.encoder.layers.10.self_attn.out_proj.weight\n",
      "model.encoder.layers.10.self_attn.out_proj.bias\n",
      "model.encoder.layers.10.self_attn_layer_norm.gamma\n",
      "model.encoder.layers.10.self_attn_layer_norm.beta\n",
      "model.encoder.layers.10.fc1.weight\n",
      "model.encoder.layers.10.fc1.bias\n",
      "model.encoder.layers.10.fc2.weight\n",
      "model.encoder.layers.10.fc2.bias\n",
      "model.encoder.layers.10.final_layer_norm.gamma\n",
      "model.encoder.layers.10.final_layer_norm.beta\n",
      "model.encoder.layers.11.self_attn.k_proj.weight\n",
      "model.encoder.layers.11.self_attn.k_proj.bias\n",
      "model.encoder.layers.11.self_attn.v_proj.weight\n",
      "model.encoder.layers.11.self_attn.v_proj.bias\n",
      "model.encoder.layers.11.self_attn.q_proj.weight\n",
      "model.encoder.layers.11.self_attn.q_proj.bias\n",
      "model.encoder.layers.11.self_attn.out_proj.weight\n",
      "model.encoder.layers.11.self_attn.out_proj.bias\n",
      "model.encoder.layers.11.self_attn_layer_norm.gamma\n",
      "model.encoder.layers.11.self_attn_layer_norm.beta\n",
      "model.encoder.layers.11.fc1.weight\n",
      "model.encoder.layers.11.fc1.bias\n",
      "model.encoder.layers.11.fc2.weight\n",
      "model.encoder.layers.11.fc2.bias\n",
      "model.encoder.layers.11.final_layer_norm.gamma\n",
      "model.encoder.layers.11.final_layer_norm.beta\n",
      "model.encoder.layernorm_embedding.gamma\n",
      "model.encoder.layernorm_embedding.beta\n",
      "model.decoder.embed_positions.embedding_table\n",
      "model.decoder.layers.0.self_attn.k_proj.weight\n",
      "model.decoder.layers.0.self_attn.k_proj.bias\n",
      "model.decoder.layers.0.self_attn.v_proj.weight\n",
      "model.decoder.layers.0.self_attn.v_proj.bias\n",
      "model.decoder.layers.0.self_attn.q_proj.weight\n",
      "model.decoder.layers.0.self_attn.q_proj.bias\n",
      "model.decoder.layers.0.self_attn.out_proj.weight\n",
      "model.decoder.layers.0.self_attn.out_proj.bias\n",
      "model.decoder.layers.0.self_attn_layer_norm.gamma\n",
      "model.decoder.layers.0.self_attn_layer_norm.beta\n",
      "model.decoder.layers.0.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.0.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.0.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.0.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.0.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.0.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.0.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.0.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.0.encoder_attn_layer_norm.gamma\n",
      "model.decoder.layers.0.encoder_attn_layer_norm.beta\n",
      "model.decoder.layers.0.fc1.weight\n",
      "model.decoder.layers.0.fc1.bias\n",
      "model.decoder.layers.0.fc2.weight\n",
      "model.decoder.layers.0.fc2.bias\n",
      "model.decoder.layers.0.final_layer_norm.gamma\n",
      "model.decoder.layers.0.final_layer_norm.beta\n",
      "model.decoder.layers.1.self_attn.k_proj.weight\n",
      "model.decoder.layers.1.self_attn.k_proj.bias\n",
      "model.decoder.layers.1.self_attn.v_proj.weight\n",
      "model.decoder.layers.1.self_attn.v_proj.bias\n",
      "model.decoder.layers.1.self_attn.q_proj.weight\n",
      "model.decoder.layers.1.self_attn.q_proj.bias\n",
      "model.decoder.layers.1.self_attn.out_proj.weight\n",
      "model.decoder.layers.1.self_attn.out_proj.bias\n",
      "model.decoder.layers.1.self_attn_layer_norm.gamma\n",
      "model.decoder.layers.1.self_attn_layer_norm.beta\n",
      "model.decoder.layers.1.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.1.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.1.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.1.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.1.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.1.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.1.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.1.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.1.encoder_attn_layer_norm.gamma\n",
      "model.decoder.layers.1.encoder_attn_layer_norm.beta\n",
      "model.decoder.layers.1.fc1.weight\n",
      "model.decoder.layers.1.fc1.bias\n",
      "model.decoder.layers.1.fc2.weight\n",
      "model.decoder.layers.1.fc2.bias\n",
      "model.decoder.layers.1.final_layer_norm.gamma\n",
      "model.decoder.layers.1.final_layer_norm.beta\n",
      "model.decoder.layers.2.self_attn.k_proj.weight\n",
      "model.decoder.layers.2.self_attn.k_proj.bias\n",
      "model.decoder.layers.2.self_attn.v_proj.weight\n",
      "model.decoder.layers.2.self_attn.v_proj.bias\n",
      "model.decoder.layers.2.self_attn.q_proj.weight\n",
      "model.decoder.layers.2.self_attn.q_proj.bias\n",
      "model.decoder.layers.2.self_attn.out_proj.weight\n",
      "model.decoder.layers.2.self_attn.out_proj.bias\n",
      "model.decoder.layers.2.self_attn_layer_norm.gamma\n",
      "model.decoder.layers.2.self_attn_layer_norm.beta\n",
      "model.decoder.layers.2.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.2.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.2.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.2.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.2.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.2.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.2.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.2.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.2.encoder_attn_layer_norm.gamma\n",
      "model.decoder.layers.2.encoder_attn_layer_norm.beta\n",
      "model.decoder.layers.2.fc1.weight\n",
      "model.decoder.layers.2.fc1.bias\n",
      "model.decoder.layers.2.fc2.weight\n",
      "model.decoder.layers.2.fc2.bias\n",
      "model.decoder.layers.2.final_layer_norm.gamma\n",
      "model.decoder.layers.2.final_layer_norm.beta\n",
      "model.decoder.layers.3.self_attn.k_proj.weight\n",
      "model.decoder.layers.3.self_attn.k_proj.bias\n",
      "model.decoder.layers.3.self_attn.v_proj.weight\n",
      "model.decoder.layers.3.self_attn.v_proj.bias\n",
      "model.decoder.layers.3.self_attn.q_proj.weight\n",
      "model.decoder.layers.3.self_attn.q_proj.bias\n",
      "model.decoder.layers.3.self_attn.out_proj.weight\n",
      "model.decoder.layers.3.self_attn.out_proj.bias\n",
      "model.decoder.layers.3.self_attn_layer_norm.gamma\n",
      "model.decoder.layers.3.self_attn_layer_norm.beta\n",
      "model.decoder.layers.3.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.3.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.3.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.3.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.3.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.3.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.3.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.3.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.3.encoder_attn_layer_norm.gamma\n",
      "model.decoder.layers.3.encoder_attn_layer_norm.beta\n",
      "model.decoder.layers.3.fc1.weight\n",
      "model.decoder.layers.3.fc1.bias\n",
      "model.decoder.layers.3.fc2.weight\n",
      "model.decoder.layers.3.fc2.bias\n",
      "model.decoder.layers.3.final_layer_norm.gamma\n",
      "model.decoder.layers.3.final_layer_norm.beta\n",
      "model.decoder.layers.4.self_attn.k_proj.weight\n",
      "model.decoder.layers.4.self_attn.k_proj.bias\n",
      "model.decoder.layers.4.self_attn.v_proj.weight\n",
      "model.decoder.layers.4.self_attn.v_proj.bias\n",
      "model.decoder.layers.4.self_attn.q_proj.weight\n",
      "model.decoder.layers.4.self_attn.q_proj.bias\n",
      "model.decoder.layers.4.self_attn.out_proj.weight\n",
      "model.decoder.layers.4.self_attn.out_proj.bias\n",
      "model.decoder.layers.4.self_attn_layer_norm.gamma\n",
      "model.decoder.layers.4.self_attn_layer_norm.beta\n",
      "model.decoder.layers.4.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.4.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.4.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.4.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.4.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.4.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.4.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.4.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.4.encoder_attn_layer_norm.gamma\n",
      "model.decoder.layers.4.encoder_attn_layer_norm.beta\n",
      "model.decoder.layers.4.fc1.weight\n",
      "model.decoder.layers.4.fc1.bias\n",
      "model.decoder.layers.4.fc2.weight\n",
      "model.decoder.layers.4.fc2.bias\n",
      "model.decoder.layers.4.final_layer_norm.gamma\n",
      "model.decoder.layers.4.final_layer_norm.beta\n",
      "model.decoder.layers.5.self_attn.k_proj.weight\n",
      "model.decoder.layers.5.self_attn.k_proj.bias\n",
      "model.decoder.layers.5.self_attn.v_proj.weight\n",
      "model.decoder.layers.5.self_attn.v_proj.bias\n",
      "model.decoder.layers.5.self_attn.q_proj.weight\n",
      "model.decoder.layers.5.self_attn.q_proj.bias\n",
      "model.decoder.layers.5.self_attn.out_proj.weight\n",
      "model.decoder.layers.5.self_attn.out_proj.bias\n",
      "model.decoder.layers.5.self_attn_layer_norm.gamma\n",
      "model.decoder.layers.5.self_attn_layer_norm.beta\n",
      "model.decoder.layers.5.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.5.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.5.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.5.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.5.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.5.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.5.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.5.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.5.encoder_attn_layer_norm.gamma\n",
      "model.decoder.layers.5.encoder_attn_layer_norm.beta\n",
      "model.decoder.layers.5.fc1.weight\n",
      "model.decoder.layers.5.fc1.bias\n",
      "model.decoder.layers.5.fc2.weight\n",
      "model.decoder.layers.5.fc2.bias\n",
      "model.decoder.layers.5.final_layer_norm.gamma\n",
      "model.decoder.layers.5.final_layer_norm.beta\n",
      "model.decoder.layers.6.self_attn.k_proj.weight\n",
      "model.decoder.layers.6.self_attn.k_proj.bias\n",
      "model.decoder.layers.6.self_attn.v_proj.weight\n",
      "model.decoder.layers.6.self_attn.v_proj.bias\n",
      "model.decoder.layers.6.self_attn.q_proj.weight\n",
      "model.decoder.layers.6.self_attn.q_proj.bias\n",
      "model.decoder.layers.6.self_attn.out_proj.weight\n",
      "model.decoder.layers.6.self_attn.out_proj.bias\n",
      "model.decoder.layers.6.self_attn_layer_norm.gamma\n",
      "model.decoder.layers.6.self_attn_layer_norm.beta\n",
      "model.decoder.layers.6.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.6.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.6.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.6.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.6.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.6.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.6.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.6.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.6.encoder_attn_layer_norm.gamma\n",
      "model.decoder.layers.6.encoder_attn_layer_norm.beta\n",
      "model.decoder.layers.6.fc1.weight\n",
      "model.decoder.layers.6.fc1.bias\n",
      "model.decoder.layers.6.fc2.weight\n",
      "model.decoder.layers.6.fc2.bias\n",
      "model.decoder.layers.6.final_layer_norm.gamma\n",
      "model.decoder.layers.6.final_layer_norm.beta\n",
      "model.decoder.layers.7.self_attn.k_proj.weight\n",
      "model.decoder.layers.7.self_attn.k_proj.bias\n",
      "model.decoder.layers.7.self_attn.v_proj.weight\n",
      "model.decoder.layers.7.self_attn.v_proj.bias\n",
      "model.decoder.layers.7.self_attn.q_proj.weight\n",
      "model.decoder.layers.7.self_attn.q_proj.bias\n",
      "model.decoder.layers.7.self_attn.out_proj.weight\n",
      "model.decoder.layers.7.self_attn.out_proj.bias\n",
      "model.decoder.layers.7.self_attn_layer_norm.gamma\n",
      "model.decoder.layers.7.self_attn_layer_norm.beta\n",
      "model.decoder.layers.7.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.7.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.7.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.7.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.7.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.7.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.7.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.7.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.7.encoder_attn_layer_norm.gamma\n",
      "model.decoder.layers.7.encoder_attn_layer_norm.beta\n",
      "model.decoder.layers.7.fc1.weight\n",
      "model.decoder.layers.7.fc1.bias\n",
      "model.decoder.layers.7.fc2.weight\n",
      "model.decoder.layers.7.fc2.bias\n",
      "model.decoder.layers.7.final_layer_norm.gamma\n",
      "model.decoder.layers.7.final_layer_norm.beta\n",
      "model.decoder.layers.8.self_attn.k_proj.weight\n",
      "model.decoder.layers.8.self_attn.k_proj.bias\n",
      "model.decoder.layers.8.self_attn.v_proj.weight\n",
      "model.decoder.layers.8.self_attn.v_proj.bias\n",
      "model.decoder.layers.8.self_attn.q_proj.weight\n",
      "model.decoder.layers.8.self_attn.q_proj.bias\n",
      "model.decoder.layers.8.self_attn.out_proj.weight\n",
      "model.decoder.layers.8.self_attn.out_proj.bias\n",
      "model.decoder.layers.8.self_attn_layer_norm.gamma\n",
      "model.decoder.layers.8.self_attn_layer_norm.beta\n",
      "model.decoder.layers.8.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.8.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.8.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.8.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.8.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.8.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.8.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.8.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.8.encoder_attn_layer_norm.gamma\n",
      "model.decoder.layers.8.encoder_attn_layer_norm.beta\n",
      "model.decoder.layers.8.fc1.weight\n",
      "model.decoder.layers.8.fc1.bias\n",
      "model.decoder.layers.8.fc2.weight\n",
      "model.decoder.layers.8.fc2.bias\n",
      "model.decoder.layers.8.final_layer_norm.gamma\n",
      "model.decoder.layers.8.final_layer_norm.beta\n",
      "model.decoder.layers.9.self_attn.k_proj.weight\n",
      "model.decoder.layers.9.self_attn.k_proj.bias\n",
      "model.decoder.layers.9.self_attn.v_proj.weight\n",
      "model.decoder.layers.9.self_attn.v_proj.bias\n",
      "model.decoder.layers.9.self_attn.q_proj.weight\n",
      "model.decoder.layers.9.self_attn.q_proj.bias\n",
      "model.decoder.layers.9.self_attn.out_proj.weight\n",
      "model.decoder.layers.9.self_attn.out_proj.bias\n",
      "model.decoder.layers.9.self_attn_layer_norm.gamma\n",
      "model.decoder.layers.9.self_attn_layer_norm.beta\n",
      "model.decoder.layers.9.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.9.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.9.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.9.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.9.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.9.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.9.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.9.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.9.encoder_attn_layer_norm.gamma\n",
      "model.decoder.layers.9.encoder_attn_layer_norm.beta\n",
      "model.decoder.layers.9.fc1.weight\n",
      "model.decoder.layers.9.fc1.bias\n",
      "model.decoder.layers.9.fc2.weight\n",
      "model.decoder.layers.9.fc2.bias\n",
      "model.decoder.layers.9.final_layer_norm.gamma\n",
      "model.decoder.layers.9.final_layer_norm.beta\n",
      "model.decoder.layers.10.self_attn.k_proj.weight\n",
      "model.decoder.layers.10.self_attn.k_proj.bias\n",
      "model.decoder.layers.10.self_attn.v_proj.weight\n",
      "model.decoder.layers.10.self_attn.v_proj.bias\n",
      "model.decoder.layers.10.self_attn.q_proj.weight\n",
      "model.decoder.layers.10.self_attn.q_proj.bias\n",
      "model.decoder.layers.10.self_attn.out_proj.weight\n",
      "model.decoder.layers.10.self_attn.out_proj.bias\n",
      "model.decoder.layers.10.self_attn_layer_norm.gamma\n",
      "model.decoder.layers.10.self_attn_layer_norm.beta\n",
      "model.decoder.layers.10.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.10.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.10.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.10.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.10.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.10.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.10.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.10.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.10.encoder_attn_layer_norm.gamma\n",
      "model.decoder.layers.10.encoder_attn_layer_norm.beta\n",
      "model.decoder.layers.10.fc1.weight\n",
      "model.decoder.layers.10.fc1.bias\n",
      "model.decoder.layers.10.fc2.weight\n",
      "model.decoder.layers.10.fc2.bias\n",
      "model.decoder.layers.10.final_layer_norm.gamma\n",
      "model.decoder.layers.10.final_layer_norm.beta\n",
      "model.decoder.layers.11.self_attn.k_proj.weight\n",
      "model.decoder.layers.11.self_attn.k_proj.bias\n",
      "model.decoder.layers.11.self_attn.v_proj.weight\n",
      "model.decoder.layers.11.self_attn.v_proj.bias\n",
      "model.decoder.layers.11.self_attn.q_proj.weight\n",
      "model.decoder.layers.11.self_attn.q_proj.bias\n",
      "model.decoder.layers.11.self_attn.out_proj.weight\n",
      "model.decoder.layers.11.self_attn.out_proj.bias\n",
      "model.decoder.layers.11.self_attn_layer_norm.gamma\n",
      "model.decoder.layers.11.self_attn_layer_norm.beta\n",
      "model.decoder.layers.11.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.11.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.11.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.11.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.11.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.11.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.11.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.11.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.11.encoder_attn_layer_norm.gamma\n",
      "model.decoder.layers.11.encoder_attn_layer_norm.beta\n",
      "model.decoder.layers.11.fc1.weight\n",
      "model.decoder.layers.11.fc1.bias\n",
      "model.decoder.layers.11.fc2.weight\n",
      "model.decoder.layers.11.fc2.bias\n",
      "model.decoder.layers.11.final_layer_norm.gamma\n",
      "model.decoder.layers.11.final_layer_norm.beta\n",
      "model.decoder.layernorm_embedding.gamma\n",
      "model.decoder.layernorm_embedding.beta\n",
      "lm_head.weight\n"
     ]
    }
   ],
   "source": [
    "# print ms_model parameters' name\n",
    "for key, param in ms_model.parameters_and_names():\n",
    "    print(param.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "def torch_to_mindspore(pth_file, size:str=None):\n",
    "    try:\n",
    "        import torch\n",
    "    except:\n",
    "        raise ImportError(f\"'import torch' failed, please install torch by \"\n",
    "                          f\"`pip install torch` or instructions from 'https://pytorch.org'\")\n",
    "\n",
    "    size = \"mindspore\" if not size else size # rename ckpt\n",
    "\n",
    "    from mindspore import Tensor\n",
    "    from mindspore.train.serialization import save_checkpoint\n",
    "\n",
    "    logging.info('Starting checkpoint conversion.')\n",
    "    ms_ckpt = []\n",
    "    state_dict = torch.load(pth_file, map_location=torch.device('cpu'))\n",
    "\n",
    "    for k, v in ms_model.parameters_and_names():\n",
    "        find_name = v.name.replace('embedding_table','weight').replace('gamma','weight').replace('beta','bias')\n",
    "        if find_name not in state_dict:\n",
    "            print(v.name)\n",
    "        if find_name in pt.BartForConditionalGeneration._keys_to_ignore_on_load_missing:\n",
    "            continue\n",
    "        ms_ckpt.append({'name': v.name, 'data': Tensor(state_dict[find_name].numpy())})\n",
    "\n",
    "    ms_ckpt_path = pth_file.replace('.bin','.ckpt')\n",
    "    ms_ckpt_path = ms_ckpt_path.replace('pytorch',size)\n",
    "    try:\n",
    "        save_checkpoint(ms_ckpt, ms_ckpt_path)\n",
    "    except:\n",
    "        raise RuntimeError(f'Save checkpoint to {ms_ckpt_path} failed, please checkout the path.')\n",
    "\n",
    "    return ms_ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_logits_bias\n",
      "lm_head.weight\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/wangxingran/bart_migration/Bartckpt/facebook/bart-large-xsum/mindspore_model.ckpt'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_to_mindspore(pytorch_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(10771:139799685108800,MainProcess):2023-04-07-19:36:05.558.288 [mindspore/train/serialization.py:1058] For 'load_param_into_net', 2 parameters in the 'net' are not loaded, because they are not in the 'parameter_dict', please check whether the network structure is consistent when training and loading checkpoint.\n",
      "[WARNING] ME(10771:139799685108800,MainProcess):2023-04-07-19:36:05.644.669 [mindspore/train/serialization.py:1060] final_logits_bias is not loaded.\n",
      "[WARNING] ME(10771:139799685108800,MainProcess):2023-04-07-19:36:05.646.144 [mindspore/train/serialization.py:1060] lm_head.weight is not loaded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param_not_load:(['final_logits_bias', 'lm_head.weight'], [])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration<\n",
       "  (model): BartModel<\n",
       "    (shared): Embedding<vocab_size=50264, embedding_size=1024, use_one_hot=False, embedding_table=Parameter (name=model.shared.embedding_table, shape=(50264, 1024), dtype=Float32, requires_grad=True), dtype=Float32, padding_idx=1>\n",
       "    (encoder): BartEncoder<\n",
       "      (embed_tokens): Embedding<vocab_size=50264, embedding_size=1024, use_one_hot=False, embedding_table=Parameter (name=model.shared.embedding_table, shape=(50264, 1024), dtype=Float32, requires_grad=True), dtype=Float32, padding_idx=1>\n",
       "      (embed_positions): BartLearnedPositionalEmbedding<vocab_size=1026, embedding_size=1024, use_one_hot=False, embedding_table=Parameter (name=model.encoder.embed_positions.embedding_table, shape=(1026, 1024), dtype=Float32, requires_grad=True), dtype=Float32, padding_idx=None>\n",
       "      (layers): CellList<\n",
       "        (0): BartEncoderLayer<\n",
       "          (self_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (self_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.encoder.layers.0.self_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.encoder.layers.0.self_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (activation_fn): GELU<>\n",
       "          (fc1): Dense<input_channels=1024, output_channels=4096, has_bias=True>\n",
       "          (fc2): Dense<input_channels=4096, output_channels=1024, has_bias=True>\n",
       "          (final_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.encoder.layers.0.final_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.encoder.layers.0.final_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          >\n",
       "        (1): BartEncoderLayer<\n",
       "          (self_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (self_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.encoder.layers.1.self_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.encoder.layers.1.self_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (activation_fn): GELU<>\n",
       "          (fc1): Dense<input_channels=1024, output_channels=4096, has_bias=True>\n",
       "          (fc2): Dense<input_channels=4096, output_channels=1024, has_bias=True>\n",
       "          (final_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.encoder.layers.1.final_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.encoder.layers.1.final_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          >\n",
       "        (2): BartEncoderLayer<\n",
       "          (self_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (self_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.encoder.layers.2.self_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.encoder.layers.2.self_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (activation_fn): GELU<>\n",
       "          (fc1): Dense<input_channels=1024, output_channels=4096, has_bias=True>\n",
       "          (fc2): Dense<input_channels=4096, output_channels=1024, has_bias=True>\n",
       "          (final_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.encoder.layers.2.final_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.encoder.layers.2.final_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          >\n",
       "        (3): BartEncoderLayer<\n",
       "          (self_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (self_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.encoder.layers.3.self_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.encoder.layers.3.self_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (activation_fn): GELU<>\n",
       "          (fc1): Dense<input_channels=1024, output_channels=4096, has_bias=True>\n",
       "          (fc2): Dense<input_channels=4096, output_channels=1024, has_bias=True>\n",
       "          (final_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.encoder.layers.3.final_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.encoder.layers.3.final_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          >\n",
       "        (4): BartEncoderLayer<\n",
       "          (self_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (self_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.encoder.layers.4.self_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.encoder.layers.4.self_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (activation_fn): GELU<>\n",
       "          (fc1): Dense<input_channels=1024, output_channels=4096, has_bias=True>\n",
       "          (fc2): Dense<input_channels=4096, output_channels=1024, has_bias=True>\n",
       "          (final_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.encoder.layers.4.final_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.encoder.layers.4.final_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          >\n",
       "        (5): BartEncoderLayer<\n",
       "          (self_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (self_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.encoder.layers.5.self_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.encoder.layers.5.self_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (activation_fn): GELU<>\n",
       "          (fc1): Dense<input_channels=1024, output_channels=4096, has_bias=True>\n",
       "          (fc2): Dense<input_channels=4096, output_channels=1024, has_bias=True>\n",
       "          (final_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.encoder.layers.5.final_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.encoder.layers.5.final_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          >\n",
       "        (6): BartEncoderLayer<\n",
       "          (self_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (self_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.encoder.layers.6.self_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.encoder.layers.6.self_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (activation_fn): GELU<>\n",
       "          (fc1): Dense<input_channels=1024, output_channels=4096, has_bias=True>\n",
       "          (fc2): Dense<input_channels=4096, output_channels=1024, has_bias=True>\n",
       "          (final_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.encoder.layers.6.final_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.encoder.layers.6.final_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          >\n",
       "        (7): BartEncoderLayer<\n",
       "          (self_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (self_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.encoder.layers.7.self_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.encoder.layers.7.self_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (activation_fn): GELU<>\n",
       "          (fc1): Dense<input_channels=1024, output_channels=4096, has_bias=True>\n",
       "          (fc2): Dense<input_channels=4096, output_channels=1024, has_bias=True>\n",
       "          (final_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.encoder.layers.7.final_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.encoder.layers.7.final_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          >\n",
       "        (8): BartEncoderLayer<\n",
       "          (self_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (self_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.encoder.layers.8.self_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.encoder.layers.8.self_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (activation_fn): GELU<>\n",
       "          (fc1): Dense<input_channels=1024, output_channels=4096, has_bias=True>\n",
       "          (fc2): Dense<input_channels=4096, output_channels=1024, has_bias=True>\n",
       "          (final_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.encoder.layers.8.final_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.encoder.layers.8.final_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          >\n",
       "        (9): BartEncoderLayer<\n",
       "          (self_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (self_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.encoder.layers.9.self_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.encoder.layers.9.self_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (activation_fn): GELU<>\n",
       "          (fc1): Dense<input_channels=1024, output_channels=4096, has_bias=True>\n",
       "          (fc2): Dense<input_channels=4096, output_channels=1024, has_bias=True>\n",
       "          (final_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.encoder.layers.9.final_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.encoder.layers.9.final_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          >\n",
       "        (10): BartEncoderLayer<\n",
       "          (self_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (self_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.encoder.layers.10.self_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.encoder.layers.10.self_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (activation_fn): GELU<>\n",
       "          (fc1): Dense<input_channels=1024, output_channels=4096, has_bias=True>\n",
       "          (fc2): Dense<input_channels=4096, output_channels=1024, has_bias=True>\n",
       "          (final_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.encoder.layers.10.final_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.encoder.layers.10.final_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          >\n",
       "        (11): BartEncoderLayer<\n",
       "          (self_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (self_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.encoder.layers.11.self_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.encoder.layers.11.self_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (activation_fn): GELU<>\n",
       "          (fc1): Dense<input_channels=1024, output_channels=4096, has_bias=True>\n",
       "          (fc2): Dense<input_channels=4096, output_channels=1024, has_bias=True>\n",
       "          (final_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.encoder.layers.11.final_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.encoder.layers.11.final_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          >\n",
       "        >\n",
       "      (layernorm_embedding): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.encoder.layernorm_embedding.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.encoder.layernorm_embedding.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "      >\n",
       "    (decoder): BartDecoder<\n",
       "      (embed_tokens): Embedding<vocab_size=50264, embedding_size=1024, use_one_hot=False, embedding_table=Parameter (name=model.shared.embedding_table, shape=(50264, 1024), dtype=Float32, requires_grad=True), dtype=Float32, padding_idx=1>\n",
       "      (embed_positions): BartLearnedPositionalEmbedding<vocab_size=1026, embedding_size=1024, use_one_hot=False, embedding_table=Parameter (name=model.decoder.embed_positions.embedding_table, shape=(1026, 1024), dtype=Float32, requires_grad=True), dtype=Float32, padding_idx=None>\n",
       "      (layers): CellList<\n",
       "        (0): BartDecoderLayer<\n",
       "          (self_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (activation_fn): GELU<>\n",
       "          (self_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.0.self_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.0.self_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (encoder_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (encoder_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.0.encoder_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.0.encoder_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (fc1): Dense<input_channels=1024, output_channels=4096, has_bias=True>\n",
       "          (fc2): Dense<input_channels=4096, output_channels=1024, has_bias=True>\n",
       "          (final_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.0.final_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.0.final_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          >\n",
       "        (1): BartDecoderLayer<\n",
       "          (self_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (activation_fn): GELU<>\n",
       "          (self_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.1.self_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.1.self_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (encoder_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (encoder_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.1.encoder_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.1.encoder_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (fc1): Dense<input_channels=1024, output_channels=4096, has_bias=True>\n",
       "          (fc2): Dense<input_channels=4096, output_channels=1024, has_bias=True>\n",
       "          (final_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.1.final_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.1.final_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          >\n",
       "        (2): BartDecoderLayer<\n",
       "          (self_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (activation_fn): GELU<>\n",
       "          (self_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.2.self_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.2.self_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (encoder_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (encoder_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.2.encoder_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.2.encoder_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (fc1): Dense<input_channels=1024, output_channels=4096, has_bias=True>\n",
       "          (fc2): Dense<input_channels=4096, output_channels=1024, has_bias=True>\n",
       "          (final_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.2.final_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.2.final_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          >\n",
       "        (3): BartDecoderLayer<\n",
       "          (self_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (activation_fn): GELU<>\n",
       "          (self_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.3.self_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.3.self_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (encoder_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (encoder_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.3.encoder_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.3.encoder_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (fc1): Dense<input_channels=1024, output_channels=4096, has_bias=True>\n",
       "          (fc2): Dense<input_channels=4096, output_channels=1024, has_bias=True>\n",
       "          (final_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.3.final_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.3.final_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          >\n",
       "        (4): BartDecoderLayer<\n",
       "          (self_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (activation_fn): GELU<>\n",
       "          (self_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.4.self_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.4.self_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (encoder_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (encoder_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.4.encoder_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.4.encoder_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (fc1): Dense<input_channels=1024, output_channels=4096, has_bias=True>\n",
       "          (fc2): Dense<input_channels=4096, output_channels=1024, has_bias=True>\n",
       "          (final_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.4.final_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.4.final_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          >\n",
       "        (5): BartDecoderLayer<\n",
       "          (self_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (activation_fn): GELU<>\n",
       "          (self_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.5.self_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.5.self_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (encoder_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (encoder_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.5.encoder_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.5.encoder_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (fc1): Dense<input_channels=1024, output_channels=4096, has_bias=True>\n",
       "          (fc2): Dense<input_channels=4096, output_channels=1024, has_bias=True>\n",
       "          (final_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.5.final_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.5.final_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          >\n",
       "        (6): BartDecoderLayer<\n",
       "          (self_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (activation_fn): GELU<>\n",
       "          (self_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.6.self_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.6.self_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (encoder_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (encoder_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.6.encoder_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.6.encoder_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (fc1): Dense<input_channels=1024, output_channels=4096, has_bias=True>\n",
       "          (fc2): Dense<input_channels=4096, output_channels=1024, has_bias=True>\n",
       "          (final_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.6.final_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.6.final_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          >\n",
       "        (7): BartDecoderLayer<\n",
       "          (self_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (activation_fn): GELU<>\n",
       "          (self_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.7.self_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.7.self_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (encoder_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (encoder_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.7.encoder_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.7.encoder_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (fc1): Dense<input_channels=1024, output_channels=4096, has_bias=True>\n",
       "          (fc2): Dense<input_channels=4096, output_channels=1024, has_bias=True>\n",
       "          (final_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.7.final_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.7.final_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          >\n",
       "        (8): BartDecoderLayer<\n",
       "          (self_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (activation_fn): GELU<>\n",
       "          (self_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.8.self_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.8.self_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (encoder_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (encoder_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.8.encoder_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.8.encoder_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (fc1): Dense<input_channels=1024, output_channels=4096, has_bias=True>\n",
       "          (fc2): Dense<input_channels=4096, output_channels=1024, has_bias=True>\n",
       "          (final_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.8.final_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.8.final_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          >\n",
       "        (9): BartDecoderLayer<\n",
       "          (self_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (activation_fn): GELU<>\n",
       "          (self_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.9.self_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.9.self_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (encoder_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (encoder_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.9.encoder_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.9.encoder_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (fc1): Dense<input_channels=1024, output_channels=4096, has_bias=True>\n",
       "          (fc2): Dense<input_channels=4096, output_channels=1024, has_bias=True>\n",
       "          (final_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.9.final_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.9.final_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          >\n",
       "        (10): BartDecoderLayer<\n",
       "          (self_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (activation_fn): GELU<>\n",
       "          (self_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.10.self_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.10.self_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (encoder_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (encoder_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.10.encoder_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.10.encoder_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (fc1): Dense<input_channels=1024, output_channels=4096, has_bias=True>\n",
       "          (fc2): Dense<input_channels=4096, output_channels=1024, has_bias=True>\n",
       "          (final_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.10.final_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.10.final_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          >\n",
       "        (11): BartDecoderLayer<\n",
       "          (self_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (activation_fn): GELU<>\n",
       "          (self_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.11.self_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.11.self_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (encoder_attn): BartAttention<\n",
       "            (k_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (v_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (q_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            (out_proj): Dense<input_channels=1024, output_channels=1024, has_bias=True>\n",
       "            >\n",
       "          (encoder_attn_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.11.encoder_attn_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.11.encoder_attn_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          (fc1): Dense<input_channels=1024, output_channels=4096, has_bias=True>\n",
       "          (fc2): Dense<input_channels=4096, output_channels=1024, has_bias=True>\n",
       "          (final_layer_norm): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layers.11.final_layer_norm.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layers.11.final_layer_norm.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "          >\n",
       "        >\n",
       "      (layernorm_embedding): LayerNorm<normalized_shape=[1024], begin_norm_axis=-1, begin_params_axis=-1, gammaParameter (name=model.decoder.layernorm_embedding.gamma, shape=(1024,), dtype=Float32, requires_grad=True), beta=Parameter (name=model.decoder.layernorm_embedding.beta, shape=(1024,), dtype=Float32, requires_grad=True)>\n",
       "      >\n",
       "    >\n",
       "  (lm_head): Dense<input_channels=1024, output_channels=50264>\n",
       "  >"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_path = f\"{path}/config.json\"\n",
    "with open(config_path, encoding='utf-8') as config:\n",
    "    config = json.load(config)\n",
    "# init config\n",
    "pt_config = pt.BartConfig(**config)\n",
    "ms_config = m.BartConfig(**config)\n",
    "\n",
    "# init model\n",
    "pt_model = pt.BartForConditionalGeneration(pt_config)\n",
    "ms_model = m.BartForConditionalGeneration(ms_config)\n",
    "\n",
    "# load parameters\n",
    "pt_dict = torch.load(f\"{path}/pytorch_model.bin\")\n",
    "pt_model.load_state_dict(pt_dict, False) \n",
    "\n",
    "ms_dict = mindspore.load_checkpoint(f\"{path}/mindspore_model.ckpt\")\n",
    "param_not_load = mindspore.load_param_into_net(ms_model, ms_dict)\n",
    "print(f\"Param_not_load:{param_not_load}\")\n",
    "\n",
    "# 手动copy\n",
    "for k,v in ms_model.parameters_and_names():\n",
    "    if v.name == 'lm_head.weight':\n",
    "        v.set_data(mindspore.Tensor(pt_model.state_dict().get(v.name).detach().numpy()))\n",
    "\n",
    "# set eval mode\n",
    "pt_model.eval()\n",
    "ms_model.set_train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 64\n",
    "batch = 4\n",
    "embed_dim = ms_config.d_model\n",
    "tgt_len = 32\n",
    "src_len = 32\n",
    "encoder_attention_heads = ms_config.encoder_attention_heads\n",
    "\n",
    "hidden_states = np.random.randn(batch,seq_len,embed_dim)\n",
    "# input_ids = np.random.randint(128,None,(batch,seq_len))\n",
    "input_ids = np.array([\n",
    "                [71, 82, 18, 33, 46, 91, 2],\n",
    "                [68, 34, 26, 58, 30, 82, 2],\n",
    "                [5, 97, 17, 39, 94, 40, 2],\n",
    "                [76, 83, 94, 25, 70, 78, 2],\n",
    "                [87, 59, 41, 35, 48, 66, 2],\n",
    "                [55, 13, 16, 58, 5, 2, 1],  # note padding\n",
    "                [64, 27, 31, 51, 12, 75, 2],\n",
    "                [52, 64, 86, 17, 83, 39, 2],\n",
    "                [48, 61, 9, 24, 71, 82, 2],\n",
    "                [26, 1, 60, 48, 22, 13, 2],\n",
    "                [21, 5, 62, 28, 14, 76, 2],\n",
    "                [45, 98, 37, 86, 59, 48, 2],\n",
    "                [70, 70, 50, 9, 28, 0, 2],\n",
    "                [70, 70, 50, 9, 28, 0, 2],\n",
    "                [70, 70, 50, 9, 28, 0, 2],\n",
    "                [70, 70, 50, 9, 28, 0, 2],\n",
    "                [70, 70, 50, 9, 28, 0, 2],\n",
    "                [70, 70, 50, 9, 28, 0, 2],\n",
    "                [70, 70, 50, 9, 28, 0, 2],\n",
    "                [70, 70, 50, 9, 28, 0, 2],\n",
    "                [70, 70, 50, 9, 28, 0, 2],\n",
    "                [70, 70, 50, 9, 28, 0, 2],\n",
    "                [70, 70, 50, 9, 28, 0, 2],\n",
    "                [70, 70, 50, 9, 28, 0, 2],\n",
    "            ])\n",
    "# attention_mask = np.random.randint(0,1,(batch,seq_len))\n",
    "attention_mask = np.random.randn(batch,1,seq_len,seq_len)\n",
    "head_mask = np.random.randint(0,1,(ms_config.encoder_layers,ms_config.encoder_attention_heads))\n",
    "layer_head_mask = np.random.randn(encoder_attention_heads)\n",
    "\n",
    "ms_hidden_states = mindspore.Tensor(hidden_states, dtype=mindspore.float32)\n",
    "ms_input_ids = mindspore.Tensor(input_ids, dtype=mindspore.int64)\n",
    "ms_attention_mask = mindspore.Tensor(attention_mask, dtype=mindspore.float32)\n",
    "ms_head_mask = mindspore.Tensor(head_mask, dtype=mindspore.bool_)\n",
    "ms_layer_head_mask = mindspore.Tensor(layer_head_mask, dtype=mindspore.float32)\n",
    "\n",
    "pt_hidden_states = torch.tensor(hidden_states, dtype=torch.float)\n",
    "pt_input_ids = torch.tensor(input_ids, dtype=torch.long)\n",
    "pt_attention_mask = torch.tensor(attention_mask, dtype=torch.float)\n",
    "pt_head_mask = torch.tensor(head_mask, dtype=torch.bool)\n",
    "pt_layer_head_mask = torch.tensor(layer_head_mask, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_out = ms_model(ms_input_ids)\n",
    "pt_out = pt_model(pt_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "-----True\n",
      "---True\n"
     ]
    }
   ],
   "source": [
    "def judge(o1, o2, loss = 1e-3, prefix = '-'):\n",
    "    prefix += '-'\n",
    "    if (isinstance(o1, tuple)):\n",
    "        assert len(o1) == len(o2)\n",
    "        for i in range(len(o1)):\n",
    "            judge(o1[i], o2[i], loss=loss, prefix=prefix)\n",
    "    elif (isinstance(o1,mindspore.Tensor)):\n",
    "        assert o1.shape == o2.shape\n",
    "        print(f\"{prefix}{np.allclose(o1.asnumpy(), o2.detach().numpy(), loss, loss)}\")\n",
    "    else:\n",
    "        print(f\"{type(o1)}-{type(o2)}:{o1==o2}\")\n",
    "\n",
    "judge(ms_out,pt_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-9.931457    0.55640894  1.4794239  ...  0.37412488  0.4712171\n",
      "   0.3184269 ]\n",
      " [-7.60198    -0.12448323  2.0910916  ... -0.3296257  -0.6810597\n",
      "  -0.7874516 ]\n",
      " [-4.9174356   0.06131339  2.9956322  ... -0.33067703 -0.46984035\n",
      "  -0.63954175]\n",
      " ...\n",
      " [-2.6086924   0.11346889  4.875864   ...  0.21028513  0.22378874\n",
      "  -0.27078193]\n",
      " [ 1.4311728  -0.53205293 10.8360815  ... -0.55372524 -0.45854667\n",
      "  -0.48365214]\n",
      " [-7.886387    0.08557969 12.221794   ... -0.63345397 -0.3903224\n",
      "  -0.03797966]]\n",
      "tensor([[-9.9315,  0.5564,  1.4794,  ...,  0.3741,  0.4712,  0.3184],\n",
      "        [-7.6020, -0.1245,  2.0911,  ..., -0.3296, -0.6811, -0.7875],\n",
      "        [-4.9174,  0.0613,  2.9956,  ..., -0.3307, -0.4698, -0.6395],\n",
      "        ...,\n",
      "        [-2.6087,  0.1135,  4.8759,  ...,  0.2103,  0.2238, -0.2708],\n",
      "        [ 1.4312, -0.5321, 10.8361,  ..., -0.5537, -0.4585, -0.4837],\n",
      "        [-7.8863,  0.0856, 12.2218,  ..., -0.6335, -0.3903, -0.0380]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(ms_out[0][0])\n",
    "print(pt_out[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mindspore_py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
